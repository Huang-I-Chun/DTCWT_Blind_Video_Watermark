{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dtcwt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5\n",
    "alpha = 5\n",
    "lowpass_str = 5\n",
    "highpass_str = 5\n",
    "embed_channel = 1 # 1: u; 2: v\n",
    "code_length = 60\n",
    "bit_to_pixel = 2 # each bit will generate bit_to_pixel*bit_to_pixel pixels\n",
    "wm_level = 4\n",
    "key = 66666\n",
    "random_placement_key = 4827\n",
    "coverimgpath = \"frame_0000.png\"\n",
    "# coverimgpath = \"/mnt/ssd1/H264_dirty_detect/video/image/life_0.png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34  60\n"
     ]
    }
   ],
   "source": [
    "# calculate the wm size that this cover image can afford \n",
    "image = cv2.imread(coverimgpath)\n",
    "# this is equal to celling(h/8)\n",
    "wm_w = (((((image.shape[0] + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2 \n",
    "wm_h = (((((image.shape[1] + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2\n",
    "if wm_w % 2 == 1:\n",
    "    wm_w += 1\n",
    "if wm_h % 2 == 1:\n",
    "    wm_h += 1\n",
    "\n",
    "print(f'{wm_w}  {wm_h}')\n",
    "\n",
    "# wm_w = 11\n",
    "# wm_h = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Key and corresponding wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_binary_string(length, random_seed=None):\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    binary_string = ''.join(random.choice('10') for _ in range(length))\n",
    "    return binary_string\n",
    "\n",
    "def generate_image(random_binary_string, width, height, n, output_filename):\n",
    "    # Create a black image\n",
    "    image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Initialize variables for tracking the position in the binary string\n",
    "    index = 0\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    # Loop until the image is completely filled\n",
    "    while row + n <= height:\n",
    "        # Check if we have scanned all bits; if so, reset the index\n",
    "        if index >= len(random_binary_string):\n",
    "            index = 0\n",
    "\n",
    "        # Determine the color based on the current bit (0 or 1)\n",
    "        color = (0, 0, 0) if random_binary_string[index] == '0' else (255, 255, 255)\n",
    "\n",
    "        # Move to the next position\n",
    "        if col + n <= width:\n",
    "            # Place the nxn block\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    x = col + j\n",
    "                    y = row + i\n",
    "                    image[y, x] = color\n",
    "            col += n\n",
    "            index += 1\n",
    "        else:\n",
    "            # print(index)\n",
    "            col = 0\n",
    "            row += n\n",
    "\n",
    "\n",
    "    # Save the generated image using OpenCV\n",
    "    cv2.imwrite(output_filename, image)\n",
    "\n",
    "def get_random_pos(big_matrix_shape, small_matrices, seed=None):\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(seed)\n",
    "    # Keep track of occupied positions\n",
    "    occupied = np.zeros(big_matrix_shape, dtype=bool)\n",
    "\n",
    "    random_position_list = []\n",
    "    \n",
    "    for small_matrix in small_matrices:\n",
    "        small_height, small_width = small_matrix.shape\n",
    "        \n",
    "        # Get all possible positions for this small matrix\n",
    "        possible_positions = [(i, j) for i in range(big_matrix_shape[0] - small_height + 1) \n",
    "                                      for j in range(big_matrix_shape[1] - small_width + 1)\n",
    "                                      if not np.any(occupied[i:i+small_height, j:j+small_width])]\n",
    "        \n",
    "\n",
    "        # If no possible position, return an error\n",
    "        if not possible_positions:\n",
    "            raise ValueError(\"No space left for the matrix of shape {}\".format(small_matrix.shape))\n",
    "        \n",
    "        # Randomly select one position\n",
    "        chosen_position = random.choice(possible_positions)\n",
    "        \n",
    "        # Place the small matrix at the chosen position\n",
    "        # big_matrix[chosen_position[0]:chosen_position[0]+small_height, \n",
    "        #            chosen_position[1]:chosen_position[1]+small_width] = small_matrix\n",
    "\n",
    "        random_position_list.append((chosen_position[0], chosen_position[0]+small_height, chosen_position[1], chosen_position[1]+small_width))\n",
    "        \n",
    "        # Mark the position as occupied\n",
    "        occupied[chosen_position[0]:chosen_position[0]+small_height, \n",
    "                 chosen_position[1]:chosen_position[1]+small_width] = True\n",
    "        \n",
    "    return random_position_list\n",
    "\n",
    "def place_random_pos(big_matrix, small_matrices, random_pos):\n",
    "    \n",
    "    for idx, small_matrix in enumerate(small_matrices):\n",
    "        small_height, small_width = small_matrix.shape\n",
    "        \n",
    "        # Place the small matrix at the chosen position\n",
    "        big_matrix[random_pos[idx][0]:random_pos[idx][1], \n",
    "                   random_pos[idx][2]:random_pos[idx][3]] = small_matrix\n",
    "\n",
    "        \n",
    "    return big_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_binary_string = generate_random_binary_string(code_length, key)\n",
    "generate_image(random_binary_string, wm_h, wm_w, bit_to_pixel, \"image/wm.png\")\n",
    "# print(random_binary_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin(a, shape):\n",
    "    if a.shape[0] % 2 == 1:\n",
    "        a = np.vstack((a, np.zeros((1, a.shape[1]))))\n",
    "    sh = shape[0], a.shape[0] // shape[0], shape[1], a.shape[1] // shape[1]\n",
    "    # print(sh)\n",
    "    return a.reshape(sh).mean(-1).mean(1)\n",
    "\n",
    "def generate_staggered_array(rows, cols, output_filename):\n",
    "    indices = np.arange(rows)[:, np.newaxis] + np.arange(cols)\n",
    "    staggered_array = indices % 2\n",
    "\n",
    "    staggered_array = staggered_array * 255\n",
    "    cv2.imwrite(output_filename, staggered_array)\n",
    "\n",
    "    # return staggered_array\n",
    "\n",
    "def recover_string_from_image(n, original_length, gray_image):\n",
    "    # Initialize variables for position tracking\n",
    "    row, col = 0, 0\n",
    "\n",
    "    # Use a list to store the detected strings in multiple passes\n",
    "    detected_strings = []\n",
    "\n",
    "    while row + n <= gray_image.shape[0]:  # Ensure we don't go beyond image boundaries\n",
    "        # Initialize an empty string for the current pass\n",
    "        current_string = \"\"\n",
    "\n",
    "        while len(current_string) < original_length and row + n <= gray_image.shape[0]:\n",
    "            # Extract the n x n block\n",
    "            block = gray_image[row : row + n, col : col + n]\n",
    "\n",
    "            avg_color = np.mean(block)\n",
    "\n",
    "            # current_string += '0' if avg_color < 127.5 else '1'\n",
    "\n",
    "            black_appear = 0\n",
    "            look_all_black = True\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if block[i, j] < 20:\n",
    "                        black_appear += 1\n",
    "                    if block[i, j] > 50:\n",
    "                        look_all_black = False\n",
    "\n",
    "            # if look_all_black:\n",
    "            #     current_string += \"0\"\n",
    "            # elif black_appear > 0 and avg_color < 127.5:\n",
    "            #     current_string += \"0\"\n",
    "            # else:\n",
    "            #     current_string += \"1\"\n",
    "            if black_appear > 0 and avg_color < 127.5:\n",
    "                current_string += \"0\"\n",
    "            else:\n",
    "                current_string += \"1\"\n",
    "\n",
    "            # Move to the next position\n",
    "            col += n\n",
    "            if col + n > gray_image.shape[1]:  # If we are at the end of a row\n",
    "                col = 0\n",
    "                row += n\n",
    "\n",
    "        while len(current_string) < original_length:\n",
    "            current_string += \"5\"\n",
    "\n",
    "        detected_strings.append(current_string)\n",
    "\n",
    "    # Calculate the final binary string using voting for each position\n",
    "    final_string = \"\"\n",
    "    for i in range(original_length):\n",
    "        ones = sum([1 for s in detected_strings if s[i] == \"1\"])\n",
    "        zeros = sum([1 for s in detected_strings if s[i] == \"0\"])\n",
    "\n",
    "        # If there are more ones than zeros, append '1', else append '0'.\n",
    "        # If there's a tie, append a random choice\n",
    "        if ones > zeros:\n",
    "            final_string += \"1\"\n",
    "        elif zeros > ones:\n",
    "            final_string += \"0\"\n",
    "        else:\n",
    "            final_string += np.random.choice([\"0\", \"1\"])\n",
    "\n",
    "    return final_string\n",
    "\n",
    "def embed_frame(frame, wm_coeffs):\n",
    "    img = cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # # DTCWT for V channel\n",
    "    v_transform = dtcwt.Transform2d()\n",
    "    v_coeffs = v_transform.forward(img[:, :, 2], nlevels=3)\n",
    "\n",
    "    # DTCWT for U channel\n",
    "    img_transform = dtcwt.Transform2d()\n",
    "    img_coeffs = img_transform.forward(img[:, :, 1], nlevels=3)\n",
    "\n",
    "    # DTCWT for Y Channel\n",
    "    y_transform = dtcwt.Transform2d()\n",
    "    y_coeffs = y_transform.forward(img[:, :, 0], nlevels=3)\n",
    "\n",
    "    # # Masks for the level 3 subbands\n",
    "    masks3 = [0 for i in range(6)]\n",
    "    shape3 = y_coeffs.highpasses[2][:, :, 0].shape\n",
    "\n",
    "    # embed watermark highpass into U channel's highpass\n",
    "    for i in range(6):\n",
    "        masks3[i] = cv2.filter2D(\n",
    "            np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        masks3[i] = np.ceil(rebin(masks3[i], shape3) * (1 / step))\n",
    "        # print(masks3[i])\n",
    "        masks3[i] *= 1.0 / max(12.0, np.amax(masks3[i]))\n",
    "        # print(masks3[i].shape) (135, 240)\n",
    "\n",
    "    small_matrixs = []\n",
    "    for lv in range(wm_level):\n",
    "        # 4 times redudant in each level\n",
    "        small_matrixs.append(wm_coeffs.highpasses[lv][:, :, 0])\n",
    "        small_matrixs.append(wm_coeffs.highpasses[lv][:, :, 0])\n",
    "        small_matrixs.append(wm_coeffs.highpasses[lv][:, :, 0])\n",
    "        small_matrixs.append(wm_coeffs.highpasses[lv][:, :, 0])\n",
    "\n",
    "    random_positions = get_random_pos(masks3[0].shape, small_matrixs, random_placement_key)\n",
    "        \n",
    "    for i in range(6):\n",
    "        coeffs = np.zeros(masks3[i].shape, dtype=\"complex_\")\n",
    "\n",
    "        small_matrixs = []\n",
    "        for lv in range(wm_level):\n",
    "            small_matrixs.append(wm_coeffs.highpasses[lv][:, :, i])\n",
    "            small_matrixs.append(wm_coeffs.highpasses[lv][:, :, i])\n",
    "            small_matrixs.append(wm_coeffs.highpasses[lv][:, :, i])\n",
    "            small_matrixs.append(wm_coeffs.highpasses[lv][:, :, i])\n",
    "\n",
    "        coeffs = place_random_pos(coeffs, small_matrixs, random_positions)\n",
    "        img_coeffs.highpasses[2][:, :, i] += highpass_str * (masks3[i] * coeffs)\n",
    "\n",
    "    ### embed watermark lowpass into V channel's highpass[2] (highpass as mask)\n",
    "    lowpass_masks = [0 for i in range(6)]\n",
    "\n",
    "    for i in range(4):\n",
    "        lowpass_masks[i] = cv2.filter2D(\n",
    "            np.abs(\n",
    "                np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            ),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        lowpass_masks[i] = np.ceil(\n",
    "            rebin(lowpass_masks[i], v_coeffs.highpasses[2].shape) * (1 / step)\n",
    "        )\n",
    "        lowpass_masks[i] *= 1.0 / max(12.0, np.amax(lowpass_masks[i]))\n",
    "\n",
    "    lv1_h = wm_coeffs.highpasses[0][:, :, i].shape[0]\n",
    "    lv1_w = wm_coeffs.highpasses[0][:, :, i].shape[1]\n",
    "    for i in range(4):\n",
    "        coeff = wm_coeffs.lowpass\n",
    "        # print(coeff.shape) (68, 120)\n",
    "        h, w = coeff.shape\n",
    "        coeffs = np.zeros(lowpass_masks[i].shape)\n",
    "        coeffs[2*lv1_h:2*lv1_h + h, 2*lv1_w:2*lv1_w + w] = coeff\n",
    "        v_coeffs.highpasses[2][:, :, i] += lowpass_str * (lowpass_masks[i] * coeffs)\n",
    "\n",
    "    img[:, :, 1] = img_transform.inverse(img_coeffs)\n",
    "    img[:, :, 2] = img_transform.inverse(v_coeffs)\n",
    "    ### embed watermark lowpass into V channel's highpass[2] end\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_YUV2BGR)\n",
    "    img = np.clip(img, a_min=0, a_max=255)\n",
    "    img = np.around(img).astype(np.uint8)\n",
    "\n",
    "    return img\n",
    "\n",
    "def decode_frame(wmed_img):\n",
    "    wmed_img = cv2.cvtColor(wmed_img.astype(np.float32), cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    wmed_transform = dtcwt.Transform2d()\n",
    "    wmed_coeffs = wmed_transform.forward(wmed_img[:, :, 1], nlevels=3)\n",
    "\n",
    "    y_transform = dtcwt.Transform2d()\n",
    "    y_coeffs = y_transform.forward(wmed_img[:, :, 0], nlevels=3)\n",
    "\n",
    "    v_transform = dtcwt.Transform2d()\n",
    "    v_coeffs = v_transform.forward(wmed_img[:, :, 2], nlevels=3)\n",
    "\n",
    "    masks3 = [0 for i in range(6)]\n",
    "    inv_masks3 = [0 for i in range(6)]\n",
    "    shape3 = y_coeffs.highpasses[2][:, :, 0].shape\n",
    "    for i in range(6):\n",
    "        masks3[i] = cv2.filter2D(\n",
    "            np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        masks3[i] = np.ceil(rebin(masks3[i], shape3) * (1.0 / step))\n",
    "        masks3[i][masks3[i] == 0] = 0.01\n",
    "        masks3[i] *= 1.0 / max(12.0, np.amax(masks3[i]))\n",
    "        inv_masks3[i] = 1.0 / masks3[i]\n",
    "\n",
    "    shape = wmed_coeffs.highpasses[2][:, :, i].shape\n",
    "\n",
    "    my_highpass = []\n",
    "    h, w = (((shape[0] + 1) // 2 + 1) // 2 + 1) // 2, (((shape[1] + 1) // 2 + 1) // 2 + 1) // 2\n",
    "    \n",
    "    for i in range(wm_level):\n",
    "        my_highpass.append(np.zeros((h, w, 6), dtype=\"complex_\"))\n",
    "        h = (h + 1) // 2 \n",
    "        w = (w + 1) // 2\n",
    "        # print(my_highpass[i].shape)\n",
    "\n",
    "\n",
    "    small_matrixs = []\n",
    "    for lv in range(wm_level):\n",
    "        # 4 times redudant in each level\n",
    "        small_matrixs.append(my_highpass[lv][:, :, 0])\n",
    "        small_matrixs.append(my_highpass[lv][:, :, 0])\n",
    "        small_matrixs.append(my_highpass[lv][:, :, 0])\n",
    "        small_matrixs.append(my_highpass[lv][:, :, 0])\n",
    "\n",
    "    random_positions = get_random_pos(inv_masks3[0].shape, small_matrixs, random_placement_key)\n",
    "\n",
    "    for i in range(6):\n",
    "        coeff = (wmed_coeffs.highpasses[2][:, :, i]) * inv_masks3[i] * 1 / highpass_str\n",
    "\n",
    "        for lv in range(wm_level):\n",
    "            my_highpass[lv][:, :, i] = (\n",
    "                coeff[random_positions[lv * 4][0]: random_positions[lv * 4][1], random_positions[lv * 4][2]: random_positions[lv * 4][3]] + \n",
    "                coeff[random_positions[lv * 4 + 1][0]: random_positions[lv * 4 + 1][1], random_positions[lv * 4 + 1][2]: random_positions[lv * 4 + 1][3]] + \n",
    "                coeff[random_positions[lv * 4 + 2][0]: random_positions[lv * 4 + 2][1], random_positions[lv * 4 + 2][2]: random_positions[lv * 4 + 2][3]] + \n",
    "                coeff[random_positions[lv * 4 + 3][0]: random_positions[lv * 4 + 3][1], random_positions[lv * 4 + 3][2]: random_positions[lv * 4 + 3][3]]\n",
    "            ) \n",
    "\n",
    "    highpasses = tuple(my_highpass)\n",
    "\n",
    "\n",
    "    ### extract watermark lowpass into V channel's highpass[2] (highpass as mask)\n",
    "    lowpass_masks = [0 for i in range(6)]\n",
    "    inv_lowpass_masks = [0 for i in range(6)]\n",
    "\n",
    "    for i in range(4):\n",
    "        lowpass_masks[i] = cv2.filter2D(\n",
    "            np.abs(\n",
    "                np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            ),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        lowpass_masks[i] = np.ceil(\n",
    "            rebin(lowpass_masks[i], v_coeffs.highpasses[2].shape) * (1 / step)\n",
    "        )\n",
    "        lowpass_masks[i] *= 1.0 / max(12.0, np.amax(lowpass_masks[i]))\n",
    "        lowpass_masks[i][lowpass_masks[i] == 0] = 0.01\n",
    "        inv_lowpass_masks[i] = 1.0 / lowpass_masks[i]\n",
    "\n",
    "    \n",
    "    lowpass = np.zeros((my_highpass[-1].shape[0] * 2, my_highpass[-1].shape[1] * 2), dtype=\"complex_\")\n",
    "\n",
    "    for i in range(4):\n",
    "        coeff = (v_coeffs.highpasses[2][:, :, i]) * inv_masks3[i] * 1 / highpass_str\n",
    "        lowpass[:, :] += coeff[2*my_highpass[0].shape[0]: 2*my_highpass[0].shape[0] + 2 * my_highpass[-1].shape[0], 2*my_highpass[0].shape[1]: 2*my_highpass[0].shape[1] + 2 * my_highpass[-1].shape[1]]\n",
    "\n",
    "\n",
    "    lowpass = lowpass.real.astype(np.float32)\n",
    "\n",
    "    t = dtcwt.Transform2d()\n",
    "    wm = t.inverse(dtcwt.Pyramid(lowpass, highpasses))\n",
    "\n",
    "    recovered_string = recover_string_from_image(bit_to_pixel, code_length, wm)\n",
    "    return recovered_string, wm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode a watermark.png into a cover image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverimgpath = \"frame_0000.png\"\n",
    "img = cv2.imread(coverimgpath)\n",
    "\n",
    "wm = cv2.imread(\"image/wm.png\")\n",
    "wm = cv2.cvtColor(wm, cv2.COLOR_BGR2GRAY)\n",
    "wm_transform = dtcwt.Transform2d()\n",
    "wm_coeffs = wm_transform.forward(wm, nlevels=wm_level)\n",
    "\n",
    "\n",
    "wm_img = embed_frame(img, wm_coeffs)\n",
    "cv2.imwrite(f\"image/wm_img.png\", wm_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the watermark for wm_img.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_image_path = \"image/wm_img.png\"\n",
    "wmed_img = cv2.imread(wm_image_path)\n",
    "recovered_string, recover_wm = decode_frame(wmed_img)\n",
    "\n",
    "# print(recover_wm.shape)\n",
    "# print(recovered_string)\n",
    "cv2.imwrite(f'image/wm_extract.png', recover_wm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recover key from wm_extract.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_differences(original_string, recovered_string):\n",
    "#     # Ensure both strings are of the same length\n",
    "#     if len(original_string) != len(recovered_string):\n",
    "#         raise ValueError(\"Both strings must have the same length.\")\n",
    "\n",
    "#     # Find the indices of differences\n",
    "#     diff_indices = [i for i, (orig, rec) in enumerate(zip(original_string, recovered_string)) if orig != rec]\n",
    "    \n",
    "#     # Print the differing indices\n",
    "#     if diff_indices:\n",
    "#         print(f\"Differences found at indices: {', '.join(map(str, diff_indices))}\")\n",
    "#         for idx in diff_indices:\n",
    "#             print(f'{original_string[idx] }', end=' ')\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(\"No differences found.\")\n",
    "    \n",
    "#     return len(diff_indices)\n",
    "\n",
    "# generate_image(recovered_string, wm_h, wm_w, bit_to_pixel, \"recovery_wm.png\")\n",
    "# print(f'differ length: {count_differences(random_binary_string, recovered_string)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(recovered_string)\n",
    "# print(random_binary_string)\n",
    "# print(recovered_string[19])\n",
    "# print(random_binary_string[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_wm_path = \"/mnt/ssd1/H264_dirty_detect/Experiment/wm/speed_bag_300_wm_k2486_cl60_wl4_crf1.png\"\n",
    "\n",
    "# test_wm = cv2.imread(test_wm_path)\n",
    "# test_wm = cv2.cvtColor(test_wm, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# test_recovered_string = recover_string_from_image(bit_to_pixel, code_length, test_wm)\n",
    "# generate_image(test_recovered_string, wm_h, wm_w, bit_to_pixel, \"recovery_wm.png\")\n",
    "# print(f'differ length: {count_differences(random_binary_string, test_recovered_string)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSNR SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i frame_0000.png -i wm_img.png -filter_complex \"psnr\" -f null - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ffmpeg-quality-metrics video/life_300_wm.mp4 ../video/life_300.mp4 --metrics psnr ssim > result/life_300_wm_2d.json\n",
    "# ! ffmpeg-quality-metrics video/park_joy_300_wm.mp4 ../video/park_joy_300.mp4 --metrics psnr ssim > result/park_joy_300_wm_2d.json\n",
    "# ! ffmpeg-quality-metrics video/pedestrian_area_300_wm.mp4 ../video/pedestrian_area_300.mp4 --metrics psnr ssim > result/pedestrian_area_300_wm_2d.json\n",
    "# ! ffmpeg-quality-metrics video/speed_bag_300_wm.mp4 ../video/speed_bag_300.mp4 --metrics psnr ssim > result/speed_bag_300_wm_2d.json\n",
    "\n",
    "\n",
    "# ! ffmpeg-quality-metrics ../video/life_300_wm_k2486_cl60_wl4.mp4 ../video/life_300.mp4 --metrics psnr ssim > result/life_300_wm_k2486_cl60_wl4.json\n",
    "# ! ffmpeg-quality-metrics ../video/park_joy_300_wm_k2486_cl60_wl4.mp4 ../video/park_joy_300.mp4 --metrics psnr ssim > result/park_joy_300_wm_k2486_cl60_wl4.json\n",
    "# ! ffmpeg-quality-metrics ../video/pedestrian_area_300_wm_k2486_cl60_wl4.mp4 ../video/pedestrian_area_300.mp4 --metrics psnr ssim > result/pedestrian_area_300_wm_k2486_cl60_wl4.json\n",
    "# ! ffmpeg-quality-metrics ../video/speed_bag_300_wm_k2486_cl60_wl4.mp4 ../video/speed_bag_300.mp4 --metrics psnr ssim > result/speed_bag_300_wm_k2486_cl60_wl4.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "# def worker_function(x, y):\n",
    "#     return x + y\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     pool = multiprocessing.Pool(processes=4)\n",
    "#     input_values = [(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60)]\n",
    "#     results = pool.starmap(worker_function, input_values)\n",
    "    \n",
    "#     # Results are in the same order as input_values\n",
    "#     print(results)\n",
    "    \n",
    "#     pool.close()\n",
    "#     pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Define your binary strings\n",
    "# str1 = '10101011111'\n",
    "# str2 = '10101011011'\n",
    "\n",
    "# # Convert binary strings to numpy arrays of integers\n",
    "# arr1 = np.array([int(bit) for bit in str1])\n",
    "# arr2 = np.array([int(bit) for bit in str2])\n",
    "\n",
    "# # Calculate the means of the arrays\n",
    "# mean1 = np.mean(arr1)\n",
    "# mean2 = np.mean(arr2)\n",
    "\n",
    "# # Calculate the numerator and denominator\n",
    "# numerator = np.sum((arr1 - mean1) * (arr2 - mean2))\n",
    "# denominator = np.sqrt(np.sum((arr1 - mean1) ** 2) * np.sum((arr2 - mean2) ** 2))\n",
    "\n",
    "# # Calculate the normalized correlation coefficient\n",
    "# corr_coefficient = numerator / denominator\n",
    "\n",
    "# print(f\"Normalized Correlation Coefficient: {corr_coefficient:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def normalized_cross_correlation_zero_lag(A_str, B_str):\n",
    "#     # Convert strings to numpy arrays\n",
    "#     A = np.array([int(i) for i in A_str])\n",
    "#     B = np.array([int(j) for j in B_str])\n",
    "    \n",
    "#     # Compute mean values\n",
    "#     mean_A = A.mean()\n",
    "#     mean_B = B.mean()\n",
    "\n",
    "#     numerator = np.sum((A - mean_A) * (B - mean_B))\n",
    "#     denominator = np.sqrt(np.sum((A - mean_A)**2) * np.sum((B - mean_B)**2))\n",
    "    \n",
    "#     if denominator == 0:\n",
    "#         ncc = 0\n",
    "#     else:\n",
    "#         ncc = numerator / denominator\n",
    "\n",
    "#     return ncc\n",
    "\n",
    "# # Example usage\n",
    "# A = \"101011\"\n",
    "# B = \"101111\"\n",
    "\n",
    "\n",
    "# print(normalized_cross_correlation_zero_lag(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2. 2. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 2. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 2. 2. 2. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 3. 3. 3. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 3. 3. 3. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def place_matrices(big_matrix, small_matrices, seed=None):\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Keep track of occupied positions\n",
    "    occupied = np.zeros_like(big_matrix, dtype=bool)\n",
    "    \n",
    "    for small_matrix in small_matrices:\n",
    "        small_height, small_width = small_matrix.shape\n",
    "        \n",
    "        # Get all possible positions for this small matrix\n",
    "        possible_positions = [(i, j) for i in range(big_matrix.shape[0] - small_height + 1) \n",
    "                                      for j in range(big_matrix.shape[1] - small_width + 1)\n",
    "                                      if not np.any(occupied[i:i+small_height, j:j+small_width])]\n",
    "        \n",
    "        # If no possible position, return an error\n",
    "        if not possible_positions:\n",
    "            raise ValueError(\"No space left for the matrix of shape {}\".format(small_matrix.shape))\n",
    "        \n",
    "        # Randomly select one position\n",
    "        chosen_position = random.choice(possible_positions)\n",
    "        \n",
    "        # Place the small matrix at the chosen position\n",
    "        big_matrix[chosen_position[0]:chosen_position[0]+small_height, \n",
    "                   chosen_position[1]:chosen_position[1]+small_width] = small_matrix\n",
    "        \n",
    "        # Mark the position as occupied\n",
    "        occupied[chosen_position[0]:chosen_position[0]+small_height, \n",
    "                 chosen_position[1]:chosen_position[1]+small_width] = True\n",
    "        \n",
    "    return big_matrix\n",
    "\n",
    "# Example\n",
    "big_matrix = np.zeros((10, 10))\n",
    "small_matrices = [np.ones((2, 2)), np.ones((3, 3)) * 2, np.ones((2, 3)) * 3]\n",
    "\n",
    "result = place_matrices(big_matrix, small_matrices, seed=42)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
