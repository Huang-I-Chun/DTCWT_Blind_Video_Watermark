{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dtcwt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5\n",
    "alpha = 5\n",
    "lowpass_str = 5\n",
    "highpass_str = 5\n",
    "embed_channel = 1 # 1: u; 2: v\n",
    "code_length = 60\n",
    "bit_to_pixel = 2 # each bit will generate bit_to_pixel*bit_to_pixel pixels\n",
    "wm_level = 4\n",
    "key = 8745\n",
    "random_placement_key = 9260\n",
    "coverimgpath = \"frame_0000.png\"\n",
    "# coverimgpath = \"/mnt/ssd1/H264_dirty_detect/video/image/life_0.png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34  60\n"
     ]
    }
   ],
   "source": [
    "# calculate the wm size that this cover image can afford \n",
    "image = cv2.imread(coverimgpath)\n",
    "# this is equal to celling(h/8)\n",
    "wm_w = (((((image.shape[0] + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2 \n",
    "wm_h = (((((image.shape[1] + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2 + 1) // 2\n",
    "if wm_w % 2 == 1:\n",
    "    wm_w += 1\n",
    "if wm_h % 2 == 1:\n",
    "    wm_h += 1\n",
    "\n",
    "print(f'{wm_w}  {wm_h}')\n",
    "\n",
    "# wm_w = 11\n",
    "# wm_h = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Key and corresponding wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_binary_string(length, random_seed=None):\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    binary_string = ''.join(random.choice('10') for _ in range(length))\n",
    "    return binary_string\n",
    "\n",
    "def generate_image(random_binary_string, width, height, n, output_filename):\n",
    "    # Create a black image\n",
    "    image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Initialize variables for tracking the position in the binary string\n",
    "    index = 0\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    # Loop until the image is completely filled\n",
    "    while row + n <= height:\n",
    "        # Check if we have scanned all bits; if so, reset the index\n",
    "        if index >= len(random_binary_string):\n",
    "            index = 0\n",
    "\n",
    "        # Determine the color based on the current bit (0 or 1)\n",
    "        color = (0, 0, 0) if random_binary_string[index] == '0' else (255, 255, 255)\n",
    "\n",
    "        # Move to the next position\n",
    "        if col + n <= width:\n",
    "            # Place the nxn block\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    x = col + j\n",
    "                    y = row + i\n",
    "                    image[y, x] = color\n",
    "            col += n\n",
    "            index += 1\n",
    "        else:\n",
    "            # print(index)\n",
    "            col = 0\n",
    "            row += n\n",
    "\n",
    "\n",
    "    # Save the generated image using OpenCV\n",
    "    cv2.imwrite(output_filename, image)\n",
    "\n",
    "def get_random_pos(big_matrix_shape, small_matrices, seed=None):\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(seed)\n",
    "    # Keep track of occupied positions\n",
    "    occupied = np.zeros(big_matrix_shape, dtype=bool)\n",
    "\n",
    "    random_position_list = []\n",
    "    \n",
    "    for small_matrix in small_matrices:\n",
    "        small_height, small_width = small_matrix.shape\n",
    "        \n",
    "        # Get all possible positions for this small matrix\n",
    "        possible_positions = [(i, j) for i in range(big_matrix_shape[0] - small_height + 1) \n",
    "                                      for j in range(big_matrix_shape[1] - small_width + 1)\n",
    "                                      if not np.any(occupied[i:i+small_height, j:j+small_width])]\n",
    "        \n",
    "\n",
    "        # If no possible position, return an error\n",
    "        if not possible_positions:\n",
    "            raise ValueError(\"No space left for the matrix of shape {}\".format(small_matrix.shape))\n",
    "        \n",
    "        # Randomly select one position\n",
    "        chosen_position = random.choice(possible_positions)\n",
    "        \n",
    "        # Place the small matrix at the chosen position\n",
    "        # big_matrix[chosen_position[0]:chosen_position[0]+small_height, \n",
    "        #            chosen_position[1]:chosen_position[1]+small_width] = small_matrix\n",
    "\n",
    "        random_position_list.append((chosen_position[0], chosen_position[0]+small_height, chosen_position[1], chosen_position[1]+small_width))\n",
    "        \n",
    "        # Mark the position as occupied\n",
    "        occupied[chosen_position[0]:chosen_position[0]+small_height, \n",
    "                 chosen_position[1]:chosen_position[1]+small_width] = True\n",
    "        \n",
    "    return random_position_list\n",
    "\n",
    "def place_random_pos(big_matrix, small_matrices, random_pos):\n",
    "    \n",
    "    for idx, small_matrix in enumerate(small_matrices):\n",
    "        small_height, small_width = small_matrix.shape\n",
    "        \n",
    "        # Place the small matrix at the chosen position\n",
    "        big_matrix[random_pos[idx][0]:random_pos[idx][1], \n",
    "                   random_pos[idx][2]:random_pos[idx][3]] = small_matrix\n",
    "\n",
    "        \n",
    "    return big_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_binary_string = generate_random_binary_string(code_length, key)\n",
    "generate_image(random_binary_string, wm_h, wm_w, bit_to_pixel, \"image/wm.png\")\n",
    "# generate_image('1001000101', 10, 10, bit_to_pixel, \"image/wm.png\")\n",
    "\n",
    "# print(random_binary_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin(a, shape):\n",
    "    if a.shape[0] % 2 == 1:\n",
    "        a = np.vstack((a, np.zeros((1, a.shape[1]))))\n",
    "    sh = shape[0], a.shape[0] // shape[0], shape[1], a.shape[1] // shape[1]\n",
    "    # print(sh)\n",
    "    return a.reshape(sh).mean(-1).mean(1)\n",
    "\n",
    "def generate_staggered_array(rows, cols, output_filename):\n",
    "    indices = np.arange(rows)[:, np.newaxis] + np.arange(cols)\n",
    "    staggered_array = indices % 2\n",
    "\n",
    "    staggered_array = staggered_array * 255\n",
    "    cv2.imwrite(output_filename, staggered_array)\n",
    "\n",
    "    # return staggered_array\n",
    "\n",
    "def recover_string_from_image(n, original_length, gray_image):\n",
    "    # Initialize variables for position tracking\n",
    "    row, col = 0, 0\n",
    "\n",
    "    # Use a list to store the detected strings in multiple passes\n",
    "    detected_strings = []\n",
    "\n",
    "    while row + n <= gray_image.shape[0]:  # Ensure we don't go beyond image boundaries\n",
    "        # Initialize an empty string for the current pass\n",
    "        current_string = \"\"\n",
    "\n",
    "        while len(current_string) < original_length and row + n <= gray_image.shape[0]:\n",
    "            # Extract the n x n block\n",
    "            block = gray_image[row : row + n, col : col + n]\n",
    "\n",
    "            avg_color = np.mean(block)\n",
    "\n",
    "            # current_string += '0' if avg_color < 127.5 else '1'\n",
    "\n",
    "            black_appear = 0\n",
    "            look_all_black = True\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if block[i, j] < 20:\n",
    "                        black_appear += 1\n",
    "                    if block[i, j] > 50:\n",
    "                        look_all_black = False\n",
    "\n",
    "            # if look_all_black:\n",
    "            #     current_string += \"0\"\n",
    "            # elif black_appear > 0 and avg_color < 127.5:\n",
    "            #     current_string += \"0\"\n",
    "            # else:\n",
    "            #     current_string += \"1\"\n",
    "            if black_appear > 0 and avg_color < 127.5:\n",
    "                current_string += \"0\"\n",
    "            else:\n",
    "                current_string += \"1\"\n",
    "\n",
    "            # Move to the next position\n",
    "            col += n\n",
    "            if col + n > gray_image.shape[1]:  # If we are at the end of a row\n",
    "                col = 0\n",
    "                row += n\n",
    "\n",
    "        while len(current_string) < original_length:\n",
    "            current_string += \"5\"\n",
    "\n",
    "        detected_strings.append(current_string)\n",
    "\n",
    "    # Calculate the final binary string using voting for each position\n",
    "    final_string = \"\"\n",
    "    for i in range(original_length):\n",
    "        ones = sum([1 for s in detected_strings if s[i] == \"1\"])\n",
    "        zeros = sum([1 for s in detected_strings if s[i] == \"0\"])\n",
    "\n",
    "        # If there are more ones than zeros, append '1', else append '0'.\n",
    "        # If there's a tie, append a random choice\n",
    "        if ones > zeros:\n",
    "            final_string += \"1\"\n",
    "        elif zeros > ones:\n",
    "            final_string += \"0\"\n",
    "        else:\n",
    "            final_string += np.random.choice([\"0\", \"1\"])\n",
    "\n",
    "    return final_string\n",
    "\n",
    "def embed_frame(frame, wm_coeffs):\n",
    "    img = cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # # DTCWT for V channel\n",
    "    v_transform = dtcwt.Transform2d()\n",
    "    v_coeffs = v_transform.forward(img[:, :, 2], nlevels=3)\n",
    "\n",
    "    # DTCWT for U channel\n",
    "    img_transform = dtcwt.Transform2d()\n",
    "    img_coeffs = img_transform.forward(img[:, :, 1], nlevels=3)\n",
    "\n",
    "    # DTCWT for Y Channel\n",
    "    y_transform = dtcwt.Transform2d()\n",
    "    y_coeffs = y_transform.forward(img[:, :, 0], nlevels=3)\n",
    "\n",
    "    # # Masks for the level 3 subbands\n",
    "    masks3 = [0 for i in range(6)]\n",
    "    shape3 = y_coeffs.highpasses[2][:, :, 0].shape\n",
    "\n",
    "    # embed watermark highpass into U channel's highpass\n",
    "    for i in range(6):\n",
    "        masks3[i] = cv2.filter2D(\n",
    "            np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        masks3[i] = np.ceil(rebin(masks3[i], shape3) * (1 / step))\n",
    "        # print(masks3[i])\n",
    "        masks3[i] *= 1.0 / max(12.0, np.amax(masks3[i]))\n",
    "        # print(masks3[i].shape) (135, 240)\n",
    "\n",
    "    for i in range(6):\n",
    "        coeffs = np.zeros(masks3[i].shape, dtype=\"complex_\")\n",
    "\n",
    "        for lv in range(wm_level):\n",
    "            w = 0\n",
    "            h = 0\n",
    "            for m in range(lv):\n",
    "                w += wm_coeffs.highpasses[m][:, :, i].shape[1]\n",
    "                h += wm_coeffs.highpasses[m][:, :, i].shape[0]\n",
    "\n",
    "            coeffs[h:h + wm_coeffs.highpasses[lv][:, :, i].shape[0], w:w + wm_coeffs.highpasses[lv][:, :, i].shape[1]] = wm_coeffs.highpasses[lv][:, :, i]\n",
    "            coeffs[coeffs.shape[0]-h-wm_coeffs.highpasses[lv][:, :, i].shape[0]:coeffs.shape[0]-h, w:w+ wm_coeffs.highpasses[lv][:, :, i].shape[1]] = wm_coeffs.highpasses[lv][:, :, i]\n",
    "            coeffs[h:h + wm_coeffs.highpasses[lv][:, :, i].shape[0], coeffs.shape[1]-w-wm_coeffs.highpasses[lv][:, :, i].shape[1]:coeffs.shape[1]-w] = wm_coeffs.highpasses[lv][:, :, i]\n",
    "            coeffs[coeffs.shape[0]-h-wm_coeffs.highpasses[lv][:, :, i].shape[0]:coeffs.shape[0]-h, coeffs.shape[1]-w-wm_coeffs.highpasses[lv][:, :, i].shape[1]:coeffs.shape[1]-w] = wm_coeffs.highpasses[lv][:, :, i]\n",
    "\n",
    "        img_coeffs.highpasses[2][:, :, i] += highpass_str * (masks3[i] * coeffs)\n",
    "    \n",
    "    ### embed watermark lowpass into V channel's highpass[2] (highpass as mask)\n",
    "    lowpass_masks = [0 for i in range(6)]\n",
    "\n",
    "    for i in range(4):\n",
    "        lowpass_masks[i] = cv2.filter2D(\n",
    "            np.abs(\n",
    "                np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            ),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        lowpass_masks[i] = np.ceil(\n",
    "            rebin(lowpass_masks[i], v_coeffs.highpasses[2].shape) * (1 / step)\n",
    "        )\n",
    "        lowpass_masks[i] *= 1.0 / max(12.0, np.amax(lowpass_masks[i]))\n",
    "\n",
    "    lv1_h = wm_coeffs.highpasses[0][:, :, i].shape[0]\n",
    "    lv1_w = wm_coeffs.highpasses[0][:, :, i].shape[1]\n",
    "    for i in range(4):\n",
    "        coeff = wm_coeffs.lowpass\n",
    "        # print(coeff.shape) (68, 120)\n",
    "        h, w = coeff.shape\n",
    "        coeffs = np.zeros(lowpass_masks[i].shape)\n",
    "        coeffs[2*lv1_h:2*lv1_h + h, 2*lv1_w:2*lv1_w + w] = coeff\n",
    "        v_coeffs.highpasses[2][:, :, i] += lowpass_str * (lowpass_masks[i] * coeffs)\n",
    "\n",
    "    img[:, :, 1] = img_transform.inverse(img_coeffs)\n",
    "    img[:, :, 2] = img_transform.inverse(v_coeffs)\n",
    "    ### embed watermark lowpass into V channel's highpass[2] end\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_YUV2BGR)\n",
    "    img = np.clip(img, a_min=0, a_max=255)\n",
    "    img = np.around(img).astype(np.uint8)\n",
    "\n",
    "    return img\n",
    "\n",
    "def decode_frame(wmed_img):\n",
    "    wmed_img = cv2.cvtColor(wmed_img.astype(np.float32), cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    wmed_transform = dtcwt.Transform2d()\n",
    "    wmed_coeffs = wmed_transform.forward(wmed_img[:, :, 1], nlevels=3)\n",
    "\n",
    "    y_transform = dtcwt.Transform2d()\n",
    "    y_coeffs = y_transform.forward(wmed_img[:, :, 0], nlevels=3)\n",
    "\n",
    "    v_transform = dtcwt.Transform2d()\n",
    "    v_coeffs = v_transform.forward(wmed_img[:, :, 2], nlevels=3)\n",
    "\n",
    "    masks3 = [0 for i in range(6)]\n",
    "    inv_masks3 = [0 for i in range(6)]\n",
    "    shape3 = y_coeffs.highpasses[2][:, :, 0].shape\n",
    "    for i in range(6):\n",
    "        masks3[i] = cv2.filter2D(\n",
    "            np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        masks3[i] = np.ceil(rebin(masks3[i], shape3) * (1.0 / step))\n",
    "        masks3[i][masks3[i] == 0] = 0.01\n",
    "        masks3[i] *= 1.0 / max(12.0, np.amax(masks3[i]))\n",
    "        inv_masks3[i] = 1.0 / masks3[i]\n",
    "\n",
    "    shape = wmed_coeffs.highpasses[2][:, :, i].shape\n",
    "\n",
    "    my_highpass = []\n",
    "    h, w = (((shape[0] + 1) // 2 + 1) // 2 + 1) // 2, (((shape[1] + 1) // 2 + 1) // 2 + 1) // 2\n",
    "    \n",
    "    for i in range(wm_level):\n",
    "        my_highpass.append(np.zeros((h, w, 6), dtype=\"complex_\"))\n",
    "        h = (h + 1) // 2 \n",
    "        w = (w + 1) // 2\n",
    "        # print(my_highpass[i].shape)\n",
    "\n",
    "    for i in range(6):\n",
    "        coeff = (wmed_coeffs.highpasses[2][:, :, i]) * inv_masks3[i] * 1 / highpass_str\n",
    "        for lv in range(wm_level):\n",
    "            w = 0\n",
    "            h = 0\n",
    "            for m in range(lv):\n",
    "                # print(my_highpass[m].shape)\n",
    "                w += my_highpass[m].shape[1]\n",
    "                h += my_highpass[m].shape[0]\n",
    "\n",
    "\n",
    "            my_highpass[lv][:, :, i] = (\n",
    "                coeff[h:h + my_highpass[lv].shape[0], w:w + my_highpass[lv].shape[1]] +\n",
    "                coeff[coeff.shape[0]-h-my_highpass[lv].shape[0]:coeff.shape[0]-h, w:w+ my_highpass[lv].shape[1]] +\n",
    "                coeff[h:h + my_highpass[lv].shape[0], coeff.shape[1]-w-my_highpass[lv].shape[1]:coeff.shape[1]-w] +\n",
    "                coeff[coeff.shape[0]-h-my_highpass[lv].shape[0]:coeff.shape[0]-h, coeff.shape[1]-w-my_highpass[lv].shape[1]:coeff.shape[1]-w]\n",
    "            )\n",
    "\n",
    "    highpasses = tuple(my_highpass)\n",
    "\n",
    "\n",
    "    ### extract watermark lowpass into V channel's highpass[2] (highpass as mask)\n",
    "    lowpass_masks = [0 for i in range(6)]\n",
    "    inv_lowpass_masks = [0 for i in range(6)]\n",
    "\n",
    "    for i in range(4):\n",
    "        lowpass_masks[i] = cv2.filter2D(\n",
    "            np.abs(\n",
    "                np.abs(y_coeffs.highpasses[1][:, :, i]),\n",
    "            ),\n",
    "            -1,\n",
    "            np.array([[1 / 4, 1 / 4], [1 / 4, 1 / 4]]),\n",
    "        )\n",
    "        lowpass_masks[i] = np.ceil(\n",
    "            rebin(lowpass_masks[i], v_coeffs.highpasses[2].shape) * (1 / step)\n",
    "        )\n",
    "        lowpass_masks[i] *= 1.0 / max(12.0, np.amax(lowpass_masks[i]))\n",
    "        lowpass_masks[i][lowpass_masks[i] == 0] = 0.01\n",
    "        inv_lowpass_masks[i] = 1.0 / lowpass_masks[i]\n",
    "\n",
    "    \n",
    "    lowpass = np.zeros((my_highpass[-1].shape[0] * 2, my_highpass[-1].shape[1] * 2), dtype=\"complex_\")\n",
    "\n",
    "    for i in range(4):\n",
    "        coeff = (v_coeffs.highpasses[2][:, :, i]) * inv_masks3[i] * 1 / lowpass_str\n",
    "        lowpass[:, :] += coeff[2*my_highpass[0].shape[0]: 2*my_highpass[0].shape[0] + 2 * my_highpass[-1].shape[0], 2*my_highpass[0].shape[1]: 2*my_highpass[0].shape[1] + 2 * my_highpass[-1].shape[1]]\n",
    "\n",
    "\n",
    "    lowpass = lowpass.real.astype(np.float32)\n",
    "\n",
    "    t = dtcwt.Transform2d()\n",
    "    wm = t.inverse(dtcwt.Pyramid(lowpass, highpasses))\n",
    "\n",
    "    recovered_string = recover_string_from_image(bit_to_pixel, code_length, wm)\n",
    "    return recovered_string, wm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode a watermark.png into a cover image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverimgpath = \"frame_0000.png\"\n",
    "img = cv2.imread(coverimgpath)\n",
    "\n",
    "wm = cv2.imread(\"image/wm.png\")\n",
    "wm = cv2.cvtColor(wm, cv2.COLOR_BGR2GRAY)\n",
    "wm_transform = dtcwt.Transform2d()\n",
    "wm_coeffs = wm_transform.forward(wm, nlevels=wm_level)\n",
    "\n",
    "\n",
    "wm_img = embed_frame(img, wm_coeffs)\n",
    "cv2.imwrite(f\"image/wm_img.png\", wm_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/ichun/anaconda3/envs/watermark/lib/python3.8/site-packages/cv2/../../../../lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ichun/anaconda3/envs/watermark --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, png_pipe, from 'image/wm_img.png':\n",
      "  Duration: N/A, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 1920x1080, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to 'image/wm_img_640:360.png':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: png, rgb24, 640x360, q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 png\n",
      "frame=    1 fps=0.0 q=-0.0 Lsize=N/A time=00:00:00.04 bitrate=N/A speed=0.0417x    \n",
      "video:485kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "/bin/bash: /home/ichun/anaconda3/envs/watermark/lib/python3.8/site-packages/cv2/../../../../lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ichun/anaconda3/envs/watermark --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, png_pipe, from 'image/wm_img_640:360.png':\n",
      "  Duration: N/A, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 640x360, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to 'image/wm_img_640:360scaleback.png':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: png, rgb24, 1920x1080, q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 png\n",
      "frame=    1 fps=0.0 q=-0.0 Lsize=N/A time=00:00:00.04 bitrate=N/A speed=0.0664x    \n",
      "video:3286kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -i image/wm_img.png -vf \"scale=640:360\" image/wm_img_640:360.png\n",
    "!ffmpeg -y -i image/wm_img_640:360.png -vf \"scale=1920:1080\" image/wm_img_640:360scaleback.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the watermark for wm_img.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_image_path = \"image/wm_img_640:360scaleback.png\"\n",
    "wmed_img = cv2.imread(wm_image_path)\n",
    "recovered_string, recover_wm = decode_frame(wmed_img)\n",
    "\n",
    "# print(recover_wm.shape)\n",
    "# print(recovered_string)\n",
    "cv2.imwrite(f'image/wm_extract.png', recover_wm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recover key from wm_extract.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_differences(original_string, recovered_string):\n",
    "#     # Ensure both strings are of the same length\n",
    "#     if len(original_string) != len(recovered_string):\n",
    "#         raise ValueError(\"Both strings must have the same length.\")\n",
    "\n",
    "#     # Find the indices of differences\n",
    "#     diff_indices = [i for i, (orig, rec) in enumerate(zip(original_string, recovered_string)) if orig != rec]\n",
    "    \n",
    "#     # Print the differing indices\n",
    "#     if diff_indices:\n",
    "#         print(f\"Differences found at indices: {', '.join(map(str, diff_indices))}\")\n",
    "#         for idx in diff_indices:\n",
    "#             print(f'{original_string[idx] }', end=' ')\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(\"No differences found.\")\n",
    "    \n",
    "#     return len(diff_indices)\n",
    "\n",
    "# generate_image(recovered_string, wm_h, wm_w, bit_to_pixel, \"recovery_wm.png\")\n",
    "# print(f'differ length: {count_differences(random_binary_string, recovered_string)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(recovered_string)\n",
    "# print(random_binary_string)\n",
    "# print(recovered_string[19])\n",
    "# print(random_binary_string[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_wm_path = \"/mnt/ssd1/H264_dirty_detect/Experiment/wm/speed_bag_300_wm_k2486_cl60_wl4_crf1.png\"\n",
    "\n",
    "# test_wm = cv2.imread(test_wm_path)\n",
    "# test_wm = cv2.cvtColor(test_wm, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# test_recovered_string = recover_string_from_image(bit_to_pixel, code_length, test_wm)\n",
    "# generate_image(test_recovered_string, wm_h, wm_w, bit_to_pixel, \"recovery_wm.png\")\n",
    "# print(f'differ length: {count_differences(random_binary_string, test_recovered_string)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSNR SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i frame_0000.png -i wm_img.png -filter_complex \"psnr\" -f null - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ffmpeg-quality-metrics video/life_300_wm.mp4 ../video/life_300.mp4 --metrics psnr ssim > result/life_300_wm_2d.json\n",
    "# ! ffmpeg-quality-metrics video/park_joy_300_wm.mp4 ../video/park_joy_300.mp4 --metrics psnr ssim > result/park_joy_300_wm_2d.json\n",
    "# ! ffmpeg-quality-metrics video/pedestrian_area_300_wm.mp4 ../video/pedestrian_area_300.mp4 --metrics psnr ssim > result/pedestrian_area_300_wm_2d.json\n",
    "# ! ffmpeg-quality-metrics video/speed_bag_300_wm.mp4 ../video/speed_bag_300.mp4 --metrics psnr ssim > result/speed_bag_300_wm_2d.json\n",
    "\n",
    "# ! ffmpeg-quality-metrics video/life_300_wm_rpk1984_lowu_diff.mp4 ../video/life_300.mp4 --metrics psnr ssim > result/life_300_wm_rpk1984_lowu_diff_2d.json\n",
    "# ! ffmpeg-quality-metrics video/life_300_wm_rpk1984_lowu.mp4 ../video/life_300.mp4 --metrics psnr ssim > result/life_300_wm_rpk1984_lowu_2d.json\n",
    "# ! ffmpeg-quality-metrics video/life_300_wm_rpk1984.mp4 ../video/life_300.mp4 --metrics psnr ssim > result/life_300_wm_rpk1984_2d.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscale video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ichun/anaconda3/envs/watermark --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video/life_300_wm_k2486.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 30702 kb/s\n",
      "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 30700 kb/s, 30 fps, 30 tbr, 15360 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0musing SAR=8/9\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mprofile High, level 3.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0m264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=10 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'video/life_300_wm_k2486_640:320.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x320 [SAR 8:9 DAR 16:9], q=-1--1, 30 fps, 15360 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  300 fps=212 q=-1.0 Lsize=    1177kB time=00:00:09.90 bitrate= 974.1kbits/s speed=6.99x    \n",
      "video:1173kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.365677%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mframe I:3     Avg QP:22.67  size: 33801\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mframe P:87    Avg QP:25.33  size:  8734\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mframe B:210   Avg QP:30.45  size:  1615\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mconsecutive B-frames:  5.3%  2.7%  4.0% 88.0%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mmb I  I16..4:  3.7% 55.5% 40.8%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mmb P  I16..4:  1.1%  6.7%  3.6%  P16..4: 22.5% 20.2% 15.6%  0.0%  0.0%    skip:30.3%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mmb B  I16..4:  0.1%  0.6%  0.2%  B16..8: 30.5%  8.2%  2.7%  direct: 2.9%  skip:54.9%  L0:35.1% L1:50.7% BI:14.2%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0m8x8 transform intra:59.5% inter:53.6%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mcoded y,uvDC,uvAC intra: 77.9% 88.2% 63.4% inter: 13.7% 12.9% 6.9%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mi16 v,h,dc,p:  8% 56%  6% 30%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 23% 15%  7%  7%  7%  9%  7% 12%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 27% 16%  7%  6%  6%  8%  5%  9%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mi8c dc,h,v,p: 43% 32% 13% 11%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mWeighted P-Frames: Y:1.1% UV:1.1%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mref P L0: 53.9% 26.4% 11.3%  8.4%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mref B L0: 90.9%  6.7%  2.4%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mref B L1: 93.1%  6.9%\n",
      "\u001b[1;36m[libx264 @ 0x564a858e2400] \u001b[0mkb/s:960.31\n",
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ichun/anaconda3/envs/watermark --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video/life_300_wm_k2486_640:320.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:10.00, start: 0.000000, bitrate: 964 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x320 [SAR 8:9 DAR 16:9], 960 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mprofile High, level 4.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0m264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=34 lookahead_threads=5 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'video/life_300_wm_k2486_1920:1080.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 30 fps, 15360 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  300 fps= 74 q=-1.0 Lsize=    5367kB time=00:00:09.90 bitrate=4441.0kbits/s speed=2.43x    \n",
      "video:5363kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.079360%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mframe I:3     Avg QP:20.84  size:109548\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mframe P:91    Avg QP:22.57  size: 35119\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mframe B:206   Avg QP:27.58  size:  9545\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mconsecutive B-frames:  6.3%  3.3%  9.0% 81.3%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mmb I  I16..4:  9.9% 83.1%  7.0%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mmb P  I16..4:  4.1% 16.2%  0.7%  P16..4: 28.7% 10.2%  3.7%  0.0%  0.0%    skip:36.3%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mmb B  I16..4:  0.6%  1.8%  0.1%  B16..8: 24.9%  2.8%  0.5%  direct: 2.2%  skip:67.2%  L0:43.4% L1:48.8% BI: 7.7%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0m8x8 transform intra:77.1% inter:84.6%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mcoded y,uvDC,uvAC intra: 52.8% 67.6% 27.6% inter: 10.4% 12.7% 1.2%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mi16 v,h,dc,p: 19% 34%  6% 41%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 22% 16%  5%  6%  7%  6%  7%  7%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 21% 11%  6%  8%  8%  7%  6%  4%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mi8c dc,h,v,p: 43% 26% 19% 12%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mref P L0: 52.4% 21.3% 19.9%  6.4%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mref B L0: 88.3% 10.0%  1.7%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mref B L1: 95.1%  4.9%\n",
      "\u001b[1;36m[libx264 @ 0x5591b7592f00] \u001b[0mkb/s:4392.58\n"
     ]
    }
   ],
   "source": [
    "! ffmpeg -y -i video/life_300_wm_k2486.mp4 -vf \"scale=640:320\" video/life_300_wm_k2486_640:320.mp4\n",
    "! ffmpeg -y -i video/life_300_wm_k2486_640:320.mp4 -vf \"scale=1920:1080\" video/life_300_wm_k2486_1920:1080.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "# def worker_function(x, y):\n",
    "#     return x + y\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     pool = multiprocessing.Pool(processes=4)\n",
    "#     input_values = [(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60)]\n",
    "#     results = pool.starmap(worker_function, input_values)\n",
    "    \n",
    "#     # Results are in the same order as input_values\n",
    "#     print(results)\n",
    "    \n",
    "#     pool.close()\n",
    "#     pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Define your binary strings\n",
    "# str1 = '10101011111'\n",
    "# str2 = '10101011011'\n",
    "\n",
    "# # Convert binary strings to numpy arrays of integers\n",
    "# arr1 = np.array([int(bit) for bit in str1])\n",
    "# arr2 = np.array([int(bit) for bit in str2])\n",
    "\n",
    "# # Calculate the means of the arrays\n",
    "# mean1 = np.mean(arr1)\n",
    "# mean2 = np.mean(arr2)\n",
    "\n",
    "# # Calculate the numerator and denominator\n",
    "# numerator = np.sum((arr1 - mean1) * (arr2 - mean2))\n",
    "# denominator = np.sqrt(np.sum((arr1 - mean1) ** 2) * np.sum((arr2 - mean2) ** 2))\n",
    "\n",
    "# # Calculate the normalized correlation coefficient\n",
    "# corr_coefficient = numerator / denominator\n",
    "\n",
    "# print(f\"Normalized Correlation Coefficient: {corr_coefficient:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def normalized_cross_correlation_zero_lag(A_str, B_str):\n",
    "#     # Convert strings to numpy arrays\n",
    "#     A = np.array([int(i) for i in A_str])\n",
    "#     B = np.array([int(j) for j in B_str])\n",
    "    \n",
    "#     # Compute mean values\n",
    "#     mean_A = A.mean()\n",
    "#     mean_B = B.mean()\n",
    "\n",
    "#     numerator = np.sum((A - mean_A) * (B - mean_B))\n",
    "#     denominator = np.sqrt(np.sum((A - mean_A)**2) * np.sum((B - mean_B)**2))\n",
    "    \n",
    "#     if denominator == 0:\n",
    "#         ncc = 0\n",
    "#     else:\n",
    "#         ncc = numerator / denominator\n",
    "\n",
    "#     return ncc\n",
    "\n",
    "# # Example usage\n",
    "# A = \"101011\"\n",
    "# B = \"101111\"\n",
    "\n",
    "\n",
    "# print(normalized_cross_correlation_zero_lag(A, B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
